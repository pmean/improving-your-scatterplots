---
title: "Practical suggestions for improving your scatterplots"
author: "Steve Simon"
output: powerpoint_presentation
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo=FALSE)
suppressMessages(suppressWarnings(library(ggplot2)))
```

### Synopsis

+ Definition of a scatterplot
+ Options you control
  + Location
  + Size
  + Shape
  + Color

<div class="notes">

Here is the abstract associated with this talk. I don't want to read this word for word, but I am including it here so I can refer to it as necessary during the development of this presentation.

"Practical suggestions for improving your scatterplots"

"The scatterplot is a simple display of the relationship between two or sometime three variables. You have a wide range of options for displaying a scatterplot. In particular, you can control the location, size, shape, and color of the marks in your scatterplot. Careful selection among these options will allow your audience to rapidly and accurately understand this relationship. Here are some important dos and don'ts. Don't use a gradient to represent a nominal variable. Use open circles rather than closed circles if there is a lot of overprinting. Vary the size or the shape of your data marks, but not both. Always pair color with another feature in your plots. Most importantly, never blindly accept the first graph that comes out of your software program. Revise your graphs as often as you revise your writing."

</div>

### Synopsis

+ Recommendations
  + Don't use gradients for categories
  + Open circles if there is overprinting
  + Vary size or shape, not both
  + Pair color with second feature
  + Revise, revise, revise

<div class="notes">

There are five general recommendations I want to make about scatterplots.

</div>

### What software should you use?

+ Use the software you like best
+ What does your boss use?
+ What do your co-workers use?
+ What software are you most comfortable with?
  
<div class="notes">

I'm a big believer in software agnosticism, and this is something that I see in the presentations by The Analysis Factor. It is a mistake to teach as if there is only one good program for data visualization.

If you are not sure what software package to use in this class, let me offer a few suggestions. First, your boss may have a strong opinion about what software that you should use. If you make a choice that makes me happy and your boss mad, I won't be able to get you that promotion you've been hoping for.

If your boss doesn't care, see what most of your co-workers are using. They may not be as smart as I am (put on a false air of pride here) but they are a lot closer to your cubicle when this workshop ends and you have to find a quick answer.

There's also a comfort level here. Do you want a graphical user interface or a programming language? A graphical interface is great for getting work done quickly. A programming language is great for reproducibility and reusability. What fits your working style better? I don't know and it would be arrogant of me to make the presumption that I do know.

</div>

### General principles

+ Two quantifiable criteria for an effective graph
  + Speed
  + Accuracy
  
<div class="notes">

Everybody has opinions, but data trumps all. If you want to demonstrate empirically that one particular graph is more effective than another graph, you want to measure one of two things.

First, how quickly can a viewer answer a question about the graph?

Second, how accurately can a viewer answer a question about the graph?

</div>

### Example of an empirical study

:::::: {.columns}
::: {.column}
![Figure 1 from Simkin and Hatie 1987](../images/bar-and-pie-charts.png)
:::
::: {.column}
+ Simkin D, Hastie R. An Information-Processing Analysis of Graph Perception. Journal of the American Statistical Association 1987: 82(398); 454-465.
  + Which is bigger, left or right?
  + Estimate percentage for smaller value.
:::
::::::

<div class="notes">

An early example of this type of empirical study was done in 1987 by David Simkin and Reid Hastie. They showed graphs like the ones on the left, varying the size and disparity of the bars or pie wedges. They asked two questions. Looking at the the bars/wedges indicated by the dots, which is bigger the one of the left or the one on the right? What is the percentage that you would estimate for the smaller of the two?

The researchers then measured the time it took each subject to answer these questions and how accurate those answers were.

Read the paper for the full answer, but surprisingly, the pie chart turned out to be better in some settings. Better in what sense? Better in speed and accuracy.

</div>

### Hierarchy of perception

+ Visually simple tasks
  + Position
  + Length
+ Moderately difficult tasks
  + Angle/slope
  + Area
+ Very difficult tasks
  + Volume
  + Density/Saturation/Hue

<div class="notes">



</div>

### Comparison of color

![](../images/btv_snow_average01.png)

<div class="notes">

This map uses color to show average yearly snowfall in Vermont and parts of New York. One question you might ask is how much does it snow in one Vermont city versus another.

</div>

### Comparison of color

![](../images/btv_snow_average02.png)

<div class="notes">

I've magnified a northern part of the state to highlight St. Albans.

</div>

### Comparison of color

![](../images/btv_snow_average03.png)

<div class="notes">

Here's a city in the southern part of the state, Bennington. Okay, keep those two states in mind, now.

</div>

### Comparison of color

![](../images/btv_snow_average01.png)

<div class="notes">

Okay now, which city has a higher average yearly snowfall?

How much more?

Well the blue surrounding St. Albans looks to be a bit darker than the blue surrounding Bennington. So maybe it has more snow.

Now that wasn't too hard, was it?

</div>

### Vermont snowfall scatterplot

```{r vt-read}
vt <- read.table("../data/vermont-cities-snowfall.txt")
names(vt) <- c("Snowfall", "City")
color_codes <- c("red", rep("black", 5), "red", rep("black", 6))
vermont_barchart <- ggplot(vt, aes(Snowfall, City)) + 
  geom_point(color=color_codes) + 
  expand_limits(x=0) +
  ylab(" ") +
  xlab("Yearly snowfall in inches")
ggsave("../images/btv_snow_average04.png", vermont_barchart, width=6, height=3)
```

![Bar chart of yearly snowfalls in Vermont](../images/btv_snow_average04.png)

<div class="notes">

I pulled some snowfall numbers from a different website, so this data is not perfectly consistent with the maps, but it is fairly close.

But notice how much easier that question becomes when you display the snowfalls as scatterplots?

I've highlighted Bennington and St. Albans to make it a bit easier for you, but the answer is almost immediate because you are determining relative position versus shades of a color.

Now there are some caveats here. The scatterplot doesn't help much is you live outside the twelve cities listed here. You also lose the ability to see a ridge of higher snowfall running right down the middle of the state. There's also a huge amount of snow in the parts of New York just east of Lake Ontario.

So don't take this too literally, but in general some features of a graph lend themselves better to quicker and more accurate answers.

</div>


### Break #1

+ What have you learned so far
  + Two quantifiable measures: speed and accuracy
  + Hierarchy of perception
    + Relative position is easy to judge
    + Difference in color are harder to judge
+ What's coming next
  + The five dimensions of a scatterplot
  
<div class="notes">

Let's take a break here and see if there are any questions.

</div>

### A five dimensional scatterplot
  
```{r read, eval=FALSE}  
fn <- "https://dasl.datadescription.com/download/data/3437"
sa <- read.table(fn, header=TRUE, sep="\t", stringsAsFactors=FALSE)
save(sa, file="../data/saratoga_housing.RData")
write.csv(sa, "../data/saratoga_housing.csv", row.names=FALSE)
```

```{r first-plot}
load("../data/saratoga_housing.RData")
library(ggplot2)
plot_framework <- ggplot(
  sa, aes(Size, Price, shape=factor(Fireplace), color=Baths, size=Bedrooms)) +
  theme(legend.position="none") + 
  expand_limits(x=c(0, 6), y=c(0, 1000)) +
  xlab("Size of the house (thousands of square feet") +
  ylab("Price of the house (thousands of dollars")
kitchen_sink_plot <-  plot_framework + geom_point()
ggsave("../images/kitchen-sink-plot.png", kitchen_sink_plot, height=4, width=4)
```

![](../images/kitchen-sink-plot.png)

<div class="notes">

Here's a plot that shows the five features that you have available in a scatterplot. This is not a plot format that I would recommend, just one that illustrates a basic concept.

The dataset comes from a website called DASL which is short for Data And Story Library. It represents a survey of housing prices in Saratoga, New York. For each house sale, there is information about the house, such as square footaage, number of bedrooms, number of bathrooms, and whether the house has a fireplace.

</div>

### Highlight two marks

```{r second-plot}
# 724, 791
# 724, 212

n <- dim(sa)[1]
p1 <- 915
p2 <- 212
pts <- (1:n) %in% c(p1, p2)
sa$highlight <- ifelse(pts, 1, 0.06)
faded_plot <- plot_framework + geom_point(alpha=sa$highlight)
ggsave("../images/faded-plot.png", faded_plot, width=4, height=4)
```

![Plot of snowfall in Vermont with two marks highlighted](../images/faded-plot.png)

<div class="notes">

I want to highlight just two data marks in this graph to show what the five dimensions are going to be.

</div>

### X dimension <- Square footage

```{r}
x_dimension <- faded_plot + 
  geom_text(x=sa$Size[p1], y=0, label=round(sa$Size[p1], 1), size=4, color="black") +
  geom_text(x=sa$Size[p2], y=0, label=round(sa$Size[p2], 1), size=4, color="black")
ggsave("../images/x-dimension.png", x_dimension, width=4, height=4)
```

![Plot of snowfall in Vermont emphasizing X dimension](../images/x-dimension.png)

<div class="notes">

The X dimension shows the size in thousands of square feet for each house. The two houses hightlighted have 1,300 and 5,200 square feet.

</div>

### Y dimension <- Price

```{r}
y_dimension <- faded_plot + 
  geom_text(x=0.2, y=sa$Price[p1], label=round(sa$Price[p1]), size=4, color="black") +
  geom_text(x=0.2, y=sa$Price[p2], label=round(sa$Price[p2]), size=4, color="black")
ggsave("../images/y-dimension.png", y_dimension, width=4, height=4)
```

![Plot of snowfall in Vermont emphasizing Y dimension](../images/y-dimension.png)

<div class="notes">

The Y dimension shows the price in thousands of dollars for each house. The two houses hightlighted have 1,300 and 5,200 square feet.

</div>


### Size dimension <- Number of bedrooms

```{r}
size_dimension <- faded_plot + 
  geom_text(x=sa$Size[p1], y=sa$Price[p1]+75, label=sa$Bedrooms[p1], size=3, color="black") +
  geom_text(x=sa$Size[p2], y=sa$Price[p2]+75, label=sa$Bedrooms[p2], size=5, color="black")
ggsave("../images/size-dimension.png", size_dimension, width=4, height=4)
```

![Plot of snowfall in Vermont emphasizing size dimension](../images/size-dimension.png)

<div class="notes">

The size of the data mark is proportional to the number of bedrooms. The smaller of the two highlighted marks is a house with three bedrooms. The larger is a house with four bedrooms.

</div>


### Shape <- Fireplace indicator

```{r}
shape_dimension <- faded_plot + 
  geom_text(x=sa$Size[p1], y=sa$Price[p1]+75, label="No fireplace", size=4, color="black") +
  geom_text(x=sa$Size[p2], y=sa$Price[p2]+75, label="Fireplace", size=4, color="black")
ggsave("../images/shape-dimension.png", shape_dimension, width=4, height=4)
```

![Plot of snowfall in Vermont emphasizing shape dimension](../images/shape-dimension.png)

<div class="notes">

The shape of the mark indicates whether the house has a fireplace. A triangle represents a house with a fireplace and a circle represents a house with one without a fireplace.

</div>

### Color <- Number of bathrooms

```{r}
color_dimension <- faded_plot + 
  geom_text(x=sa$Size[p1], y=sa$Price[p1]+75, label=sa$Baths[p1], size=4, color=sa$Baths[p1]) +
  geom_text(x=sa$Size[p2], y=sa$Price[p2]+75, label=sa$Baths[p2], size=4, color=sa$Baths[p2])
ggsave("../images/color-dimension.png", color_dimension, width=4, height=4)
```

![Plot of snowfall in Vermont emphasizing color dimension](../images/color-dimension.png)

<div class="notes">

The color of the data mark indicats how many bathrooms a house has. The black data mark indicates only one bathroom and the blue data mark indicates four bathrooms.

</div>

### Break #2

+ What have you learned
  + Five dimensions of a scatterplot (x, y, size, shape, and color)
+ What's coming up next
  + Mitigating the problem of overprinting

<div class="notes">

Let me stop again and see if there are any questions.

</div>

### X and Y position, mitigating overprinting
+ Partial solutions
  + Open symbols
  + Small size
  + Log transformation
  + Opacity
  + Jittering

<div class="notes">

The biggest problem with many graphs is overprinting. So much data ends up producing a big black uninterpretable blob. There are several solutions that can help somewhat with overprinting.

</div>

### Mitigating overprinting: use open symbols

```{r open}
x0 <- c(12, 13, 14, 14) 
y0 <- c(12, 12, 13, 14)
artificial_data <- data.frame(
  x=c(x0, x0+15),
  y=c(y0+10, y0+10)
)
lims <- c(10, 30)
open_circles <- ggplot(artificial_data, aes(x, y)) +
  theme_void() +
  expand_limits(x=lims, y=lims) +
  geom_point(size=20, shape=rep(c(16, 1), each=4))
ggsave("../images/open-circles.png", open_circles, width=4, height=4)
```

![Comparison of solid versus open circles](../images/open-circles.png)

<div class="notes">

If you look at the figure to the left, it looks like it might be three or maybe four data marks all clustered together. There is a bit of an indentation in the southeast corner of this blog that gives a hint that it is really four rather than three data marks. The figure on the right uses open circles and you can tell much faster that there are indeed four data marks.

</div>

### Mitigating overprinting: use open symbols

:::::: {.columns}
::: {.column}
![Original scatterplot](../images/scatter-filled.png)
:::
::: {.column}
![Scatterplot with open circles](../images/scatter-open.png)
:::
::::::

<div class="notes">

Here's what open circles do to a scatter plot of square footage versus price. It only helps a little, but you can start to see the difference between regions that have a moderate amount of data versus a much larger amount of data.

</div>

### Mitigating overprinting: Use small size marks

```{r small-size}
x0 <- c(12, 13, 14, 14) 
y0 <- c(12, 12, 13, 14)
artificial_data <- data.frame(
  x=c(x0, x0+15),
  y=c(y0+10, y0+10)
)
lims <- c(10, 30)
small_size <- ggplot(artificial_data, aes(x, y)) +
  theme_void() +
  expand_limits(x=lims, y=lims) +
  geom_point(shape=16, size=rep(c(20, 7), each=4))
ggsave("../images/small-size.png", small_size, width=4, height=4)
```

![A cluster of four data marks comparing larger versus small](../images/small-size.png)

<div class="notes">

If you use smaller data marks, you will be able to separate out the four indvidual data marks in this cluster. There are disadvantages to smaller data marks. They sometimes make it easier for you to ignore outliers. They also cause problems when you want to use different shapes, as the shapes become less distinguishable for smaller sizes. But they work well for mitigating overprinting.

</div>


### Mitigating overprinting: use smaller size marks

:::::: {.columns}
::: {.column}
![Original scatterplot](../images/scatter-filled.png)
:::
::: {.column}
![Scatterplot with smaller sized symbols](../images/scatter-small.png)
:::
::::::

<div class="notes">

In the square footage by price scatterplot, the smaller marks make it much easier to see where the individual data points are.

You can shrink this down to a single pixel, if you like. The plot looks like dust specks. Sometimes that ends up revealing a lot more of what is going on near the center of the data blob.

</div>

### Mitigating overprinting: Opacity

```{r opacity}
x0 <- c(12, 13, 14, 14) 
y0 <- c(12, 12, 13, 14)
artificial_data <- data.frame(
  x=c(x0, x0+15),
  y=c(y0+10, y0+10)
)
lims <- c(10, 30)
transparent_marks <- 
  ggplot(artificial_data, aes(x, y)) +
  theme_void() +
  expand_limits(x=lims, y=lims) +
  geom_point(shape=16, size=20, alpha=rep(c(1, 0.2), each=4))
ggsave("../images/transparent-marks.png", transparent_marks, width=4, height=4)
```

![A cluster of four data marks varying the opacity](../images/transparent-marks.png)

### Mitigating overprinting: Opacity

:::::: {.columns}
::: {.column}
![Original scatterplot](../images/scatter-filled.png)
:::
::: {.column}
![Scatterplot with opacity](../images/scatter-opacity.png)
:::
::::::

<div class="notes">

Here is a comparison to fully opaque data marks to semi-transparent data marks. The effect can sometimes minimize the effect of outliers, but it does help reveal the structure of the 

</div>

### Mitigating overprinting: Log scale

```{r log-scale00}
y0 <- seq(-4, 3, length=100)
x0 <- 2^y0
artificial_data <- data.frame(
  x=x0,
  y=y0
)
log_plot00 <- 
  ggplot(artificial_data, aes(x, y)) +
    theme_void() +
    expand_limits(x=c(-2, 9), y=c(-7, 6)) +
    geom_line()
ggsave("../images/log-plot00.png", log_plot00, width=4, height=4)
```

![Log function](../images/log-plot00.png)

<div class="notes">

Often your data is crowded in the lower left corner of your graph. This is caused by skewness in your variables. A log transformation can often help in such a situation.

Here's a picture of the log function. It is steep on the left and closer to flat on the right.

</div>


### Mitigating overprinting: Log scale

```{r log-scale01}
a <- 0.3
b <- 0.8
log_plot01 <- log_plot00 + 
    geom_segment(x=a, y=-4.1, xend=a, yend=log2(a)) +
    geom_segment(x=b, y=-4.1, xend=b, yend=log2(b)) +
    geom_segment(x=-0.3, y=log2(a), xend=a, yend=log2(a)) +
    geom_segment(x=-0.3, y=log2(b), xend=b, yend=log2(b)) +
    geom_text(x=a, y=-5, label=a, angle=90) +
    geom_text(x=-1, y=log2(a), label=round(log2(a), 1)) +
    geom_text(x=b, y=-5, label=b, angle=90) +
    geom_text(x=-1, y=log2(b), label=round(log2(b), 1))
ggsave("../images/log-plot01.png", log_plot01, width=4, height=4)
```

![Log transformation of small values](../images/log-plot01.png)

<div class="notes">

The steepness on the left means that the log function tends to stretch out small values. The data points 0.3 and 0.8 are half a unit apart, but after the log transformation they are 1.4 units apart.

</div>


### Mitigating overprinting: Log scale

```{r log-scale02}
a <- 3
b <- 6
log_plot02 <- log_plot00 + 
    geom_segment(x=a, y=-4.1, xend=a, yend=log2(a)) +
    geom_segment(x=b, y=-4.1, xend=b, yend=log2(b)) +
    geom_segment(x=-0.3, y=log2(a), xend=a, yend=log2(a)) +
    geom_segment(x=-0.3, y=log2(b), xend=b, yend=log2(b)) +
    geom_text(x=a, y=-5, label=a, angle=90) +
    geom_text(x=-1, y=log2(a), label=round(log2(a), 1)) +
    geom_text(x=b, y=-5, label=b, angle=90) +
    geom_text(x=-1, y=log2(b), label=round(log2(b), 1))
ggsave("../images/log-plot02.png", log_plot02, width=4, height=4)
```

![Log transformation of large values](../images/log-plot02.png)

<div class="notes">

The relative flatness on the right means that the log function tends to squeeze large values together. The values of 3 and 6 are 3 units apart, but after a log transformation, they are only 1 unit apart.

By stretching the values stuck in a large blob in the lower left corner of the graph and squeezing the few outlying values elsewhere, you often end up with a spread of data that is much more uniform across the plotting area.

A small hint: don't try a log transformation, unless your data has a large relative range. If your largest value is not at least three times as large as your smallest value, then the log transformation is unlikely to have an impact.

Also, you can't use a log transformation if you have zeros or negative values in your data.

</div>

### Mitigating overprinting: Log scale

:::::: {.columns}
::: {.column}
![Original scatterplot](../images/scatter-filled.png)
:::
::: {.column}
![Scatterplot with log scale](../images/scatter-log.png)
:::
::::::

<div class="notes">

Notice how the plot on the log scale tends to fill up the plotting area a bit more efficiently. This helps reduce overprinting a bit.

</div>


### Mitigating overprinting: Jittering

:::::: {.columns}
::: {.column}
![Plot of bedrooms and price without jittering](../images/scatter-no-jitter.png)
:::
::: {.column}
![Scatterplot with jittering](../images/scatter-jitter.png)
:::
::::::

<div class="notes">

I have to switch to a different set of variables to better illustrate jittering. The Y axis is still price, but the X axis is now the number of bedrooms, and most of the data values are now squished together into vertical lines.

You could use a boxplot here, but jittering is also effective. Jittering is a random shift of datapoints to the left or right (sometimes up and down as well) to help spread the data out a little bit.

</div>

### Break #3

+ What you have learned
  + Strategies for mitigating overprinting
+ What's coming next
  + Issues with shape and size
  
<div class="notes">

Let's stop and see if there are any questions.

</div>

### Problem with open and closed shapes together

```{r open-and-closed}
open_closed01 <- 
  ggplot(sa, aes(Size, Price, shape=factor(Fireplace))) + 
  scale_shape_manual(values = c(1, 16)) +
  geom_point()
ggsave("../images/open-closed01.png", open_closed01, width=4, height=4)
open_closed02 <- 
  ggplot(sa, aes(Size, Price, shape=factor(Fireplace))) + 
  scale_shape_manual(values = c(16, 1)) +
  geom_point()
ggsave("../images/open-closed02.png", open_closed02, width=4, height=4)
```

:::::: {.columns}
::: {.column}
![Plot showing open and closed circles](../images/open-closed01.png)
:::
::: {.column}
![Plot showing closed and open circles](../images/open-closed02.png)
:::
::::::

<div class="notes">

In a fight between open and closed symbols, the closed symbols always win. Notice in the left side plot, it looks like most of the houses have fireplaces (Fireplace=1 is the closed circle). In the second plot, it looks like most of the houses do not have fireplaces (Fireplace=0 is the closed circle). In fact the split is pretty close to even. `r round(100*sum(sa$Fireplace)/length(sa$Fireplace))`% of the houses have fireplaces.

</div>


### Don't use too many shapes

```{r too-many-symbols}
too_many_symbols <- 
  ggplot(sa, aes(Size, Price, shape=factor(Bedrooms))) + 
  scale_shape_manual(values = 0:6) +
  geom_point()
ggsave("../images/too-many-symbols.png", too_many_symbols, width=4, height=4)
```

![Plot with seven different shapes](../images/too-many-symbols.png)

<div class="notes">

This plot has two problems. First, it uses too many symbols. It turns the graph into a kind of puzzle where you are constantly going back and forth between the legend and the graph itself because no one can remember what all seven of the symbols represent.

The second problem is that number of bedrooms is not categorical. You want the greatest distinction to be between 1 bedrooms and 7 bedrooms and differences smaller than that should have proportionately less distinction.

</div>

### An alternative with only two shapes

```{r symbol-choices}
sa$FourPlusBedrooms <- ifelse(sa$Bedrooms>=4, "4+ BR", "1-3 BR")
two_symbols <- 
  ggplot(sa, aes(Size, Price, shape=FourPlusBedrooms)) + 
  geom_point() +
  scale_shape_manual(values = c(4, 1))
ggsave("../images/two-symbols.png", two_symbols, width=4, height=4)
```

![Plot with only two shapes](../images/two-symbols.png)

<div class="notes">

Here is a better plot. You lose a bit of information by using only two shapes, but the plot is simpler and easier to interpret.

</div>


### Using text instead of symbols

```{r symbol-text01}
number_codes <- 
  ggplot(sa, aes(Size, Price, label=Bedrooms)) + 
  geom_text()
ggsave("../images/number-codes.png", number_codes, width=4, height=4)
```

![Plot using numbers in place of shapes](../images/number-codes.png)

<div class="notes">

Sometimes a simple bit of text works better than symbols. In most software system, it is pretty easy to print the actual number where mark should be. It works great for single digit numbers, and sometimes even for two digit numbers

</div>

### Using text instead of symbols

```{r symbol-text02}
sa$Fireplace_code <- ifelse(sa$Fireplace==1, "Y", "N")
letter_codes <- ggplot(sa, aes(Size, Price, label=Fireplace_code)) + 
  geom_text()
ggsave("../images/letter-codes.png", letter_codes, width=4, height=4)
```

![Plot using letter codes Y for yes and N for no](../images/letter-codes.png)

<div class="notes">

Here's another example using letters.

Other examples might be M for male and F for female, T for treatment and C for control.

</div>

### Example using size: the bubble chart

```{r size-bedrooms}
bubble_chart <- 
  ggplot(sa, aes(Size, Price, size=Bedrooms)) + 
  geom_point(shape=1)
ggsave("../images/bubble-chart.png", width=4, height=4)
```

![Plot with size representing number of bedrooms](../images/bubble-chart.png)

<div class="notes">

This plot shows how the size of the mark can indicate a third variable. In this case, it is the number of bedrooms. This type of plot is often called a bubble chart. We've seen far too many bubble charts since the start of the COVID-19 crisis, and those bubbles are getting bigger all the time.

</div>

### Size
+ Never for a categorical variable
+ Propotional to
  + Diameter?
  + Area?

<div class="notes">

Never use size for a categorical variable. You want all the categories to be equally distinguishable, and categories given the middle sizes end up looking too much alike.

If size represents a continuous variable, do you want the size to be proportion to the diameter of your circle (or the length of your square)? Or would it be better to make the area of your circle or square proportional to the data value. There's been a lot written on this, and the general consensus is to use area.

</div>

### Size and shape don't mix

```{r size-and-shape}
ggplot(sa, aes(Size, Price, size=Bedrooms, shape=factor(Fireplace))) + 
  scale_shape_manual(values = c(4, 1)) +
  geom_point()
```

### Break #4

+ What have you learned
  + Issues with shapes and sizes
+ What's coming next
  + Issues with color
  
<div class="notes">

Let's stop again and see if there are any questions.

</div> 

### Colors, Everything I know about colors, I learned in Kindergarten.

![](../images/julias-colour-wheel1.jpg)

<div class="notes">

It was probably in Kindergarten where you learned the basic way to combine primary colors. Yellow plus red equals orange, Yellow plus blue equals green. Red plus blue equals purple/violet.

It doesn't work that way on a computer screen because screens use light to create colors and lights blend in different ways than paints or crayons.

Before you tackle ths computer system for colors, you need to review binary and hexadecimal number systems.

</div>

### Colors, Codes for colors
+ #rrggbb format
  + #000000 is pure black
  + #FFFFFF is pure white
  + #FF0000 is pure red
  + #00FF00 is pure green
  + #0000FF is pure blue
+ You can mix and match to get 16,777,216 colors
  + #800080 is purple, #FF69B4 is pink, #40E0D0 is turquoise
  
<div class="notes">

The RGB format uses six hexadecimal digits to represent colors. A hexidecimal of all zeros is pure black and at the other extreme, a hexidecimal of all F's is pure white. 

The first two hexidecimal digits represent the red channel. The highest value FF for the red channel combined with zeros for the other two channels (#FF0000) equals pure red. 

The next two digits represent the green channel. #00FF00, giving the maximum to the green channel and the minimum to the other two channels produces a pure green. 

The last two digits represent the blue channel, and #0000FF represents pure blue.

You can combine these in a variety of ways. You end up with an almost unlimited number of colors. Six hexadecimal digits allow you to produce 16^6 or 16,777,216 different colors.

</div>

### Colors, Red plus green equals yellow

```{r red-plus-green}
add_colors <- function(c1, c2, c3) {
  df <- data.frame(
    x=rep(2, 3),
    y=3:1,
    b=c(c1, c2, c3)
  )
  ggplot(df, aes(x, y)) +
    geom_text(color=df$b, size=18, label=df$b) +
    expand_limits(x=c(0, 4), y=c(0, 4)) +
    geom_text(x=0.25, y=2, label="+", size=18) +
    geom_segment(x=0.75, y=1.5, xend=3.25, yend=1.5, size=3) +
    theme_void() +
    theme(
      panel.background=element_rect(fill="#808080"))
}
red_plus_green <- add_colors("#FF0000", "#00FF00", "#FFFF00")
ggsave("../images/red-plus-green.png", red_plus_green, width=4, height=4)
```

![](../images/red-plus-green.png)

<div class="notes">

Whne you combine colors in the RGB system, they become lighter in color. So if you add red light (FF in the red channel) to green light (FF in the green chanel), you get yellow, which is FF in both the red and green channels.

</div>

### Colors, Red plus blue equals magenta

```{r red-plus-blue}
a3 <- c("#FF0000", "#FF0000", "#00FF00")
b3 <- c("#00FF00", "#0000FF", "#0000FF")
c3 <- c("#FFFF00", "#FF00FF", "#00FFFF")
red_plus_blue <- add_colors("#FF0000", "#0000FF", "#FF00FF")
ggsave("../images/red-plus-blue.png", red_plus_blue, width=4, height=4)
```

![](../images/red-plus-blue.png)

<div class="notes">

Red plus blue gives you #FF00FF, which is magenta, a light purplish red.

</div>

### Colors, Green plus blue equals cyan

```{r green-plus-blue}
green_plus_blue <- add_colors("#00FF00", "#0000FF", "#00FFFF")
ggsave("../images/green-plus-blue.png", green_plus_blue, width=4, height=4)
```

![](../images/green-plus-blue.png)

<div class="notes">

Green plus blue gives you #00FFFF, which is cyan, a greenish blue color.

</div>

### Basic colors have different luminance

```{r unequal-luminance}
x <- rep(0:9, each=10)
y <- rep(0:9, 10)
co <- ifelse(x < 4.5, "#0000FF", "#FFFF00")
unequal_luminance <- 
  ggplot(data.frame(x, y), aes(x, y)) + 
  theme_void() +
  geom_point(color=co, size=22, shape="square") +
  geom_point(x=2, y=5, color="#808080", size=22) +
  geom_point(x=7, y=5, color="#808080", size=22) 
ggsave("../images/unequal-luminance.png", unequal_luminance, width=4, height=4)
```

![Gray dot on blue and yellow backgrounds](../images/unequal-luminance.png)

<div class="notes">

Among the basic colors, yellow is an outlier. It has a much higher luminance. meaning that at the same level of brightness on your computer monitor, it stimulates your optic nerves more than other colors.

This can lead to trouble. Notice the two gray dots shown on two different backgrounds. The gray in both cases is exactly halfway between black and white, but it appears darker when contrasted with yellow, because yellow has so much luminance.

</div>

### An attempt to equalize luminance

```{r equalize-luminance}
co <- ifelse(x < 4.5, "#DDDDFF", "#FFFF00")
equalize_luminance <- 
  ggplot(data.frame(x, y), aes(x, y)) + 
  theme_void() +
  geom_point(color=co, size=22, shape="square") +
  geom_point(x=2, y=5, color="#808080", size=22) +
  geom_point(x=7, y=5, color="#808080", size=22) 
ggsave("../images/equalize-luminance.png", equalize_luminance, width=4, height=4)
```

![Using a lighter shade of blue to equalize luminance](../images/equalize-luminance.png)

<div class="notes">

You can fix this by making blue lighter (closer to white).

Higher luminance colors tend to dominate a graphic image. You should try to use colors of roughly equal luminance to avoid this.

If you mix colors of different luminance, you will create artefacts that are unrelated to your data. The higher luminance colors will either tend to unfairly dominate the picture, or they will fade into the backgound and be lost.

</div>

### Color

![Image of man wearing three bold colors](../images/fashion-mistake.png)

<div class="notes">

It's a well known fasion mistake to wear too many colors at the same time. Maybe this guy could get away with it, but most of us would look like idiots if we tried to dress that way.

There's a similar lesson for data visualization.

</div>

### Recommendations, Don't overuse colors.

![Text with a variety of colors](../images/too-many-colors.png)

<div class="notes">

Naomi Robbins, an expert on data visualization, made an interesting observation. You would never make each word in a sentence a different color. So why would you make every bar, every point, and every line a different color?

Too many colors dilutes the impact that color can have.

You can use a second color to add emphasis. Or maybe a gradient between two different colors could work. Doing more than this is usually a big mistake.

</div>

### Count the fives

```{r count-nine-colors}
set.seed(123547)
n <- 30
x <- runif(n)
y <- runif(n)
z <- factor(1+floor(9*runif(n)))
df <- data.frame(x, y, z)
count_fives01 <- ggplot(df, aes(x, y, color=z)) +
  geom_text(label=z, size=6) +
  theme(legend.position="none")
ggsave("../images/count-fives01.png", count_fives01, width=4, height=4)
```

![](../images/count-fives01.png)

<div class="notes">

Here's an exercise that adapted from Olson and Bergen.

How many fives are there in this picture. I've used a different color for each number to make it easier for you to pick out any particular number. It takes a while, but you can see that there are three 5's, clustered in the lower right corner of the graph.

Did the colors help? Well, not all that much. It is hard to pick out nine colors and not have a few of them look very similar. In particular, the 5's and the 6's are pretty close, as are the 8's and the 9's.

</div>

### Count the fives

```{r count-two-colors}
set.seed(123547)
n <- 30
x <- runif(n)
y <- runif(n)
z <- factor(1+floor(9*runif(n)))
df <- data.frame(x, y, z)
co <- ifelse(z==5, "red", "black")
count_fives02 <- ggplot(df, aes(x, y)) +
  geom_text(label=z, size=6, color=co) +
  theme(legend.position="none")
ggsave("../images/count-fives02.png", count_fives02, width=4, height=4)
```

![](../images/count-fives02.png)

<div class="notes">

When you use a bit of restraint and only show two colors, you make the process of identifying all the fives much easier.

</div>

### Discrete colors

```{r discrete-colors, eval=FALSE}
library(RColorBrewer)
display.brewer.pal(9, "Dark2")
```

![Discrete color choices from RColorBrewer](../images/discrete-colors.png)

<div class="notes">

This is a nice set of colors. Each color is distinct from each other color and they are all roughly the same level of luminance. This makes the most sense for categorical data.

</div>

### Simple gradient

```{r simple-gradient, eval=FALSE}
library(RColorBrewer)
display.brewer.pal(9, "Greens")
```

![Simple gradient from RColorBrewer](../images/simple-gradient.png)


<div class="notes">

A simple gradient transitions within a single color, usually from lighter shades of that color to darker shades.

Depending on the nature of your plot, one end of the gradient will be emphasized and one end will be de-emphasized.

</div>

### Diverging gradient

```{r diverging-gradient, eval=FALSE}
display.brewer.pal(9, "RdYlGn")
```

![Diverging gradient from RColorBrewer](../images/diverging-gradient.png)

<div class="notes">

A diverging gradient moves between two distinct colors and takes a side trip in the middle to a third color. Typically, the middle color in a diverging gradient has a much higher luminence or a much lower luminence than the two extremes and is intended to fade into the background. The diverging gradient tends to emphasize the extremes and de-emphasize the middle.

</div>

### Break #5

+ What have you learned
  + Issues with color
+ What's next
  + Recommended books

<div class="notes">

Just one more break. Are there any questions?

</div>


### Recommended books

![Book cover of Visual Display of Quantitative Information](../images/tufte-bookcover.gif)

<div class="notes">

Edward Tufte is a very interesting person. Very opinionated, and right most of the time. When his book suffers, it is from an attention to a guiding principle that is so rigid that it misses out on the times when there are exceptions to every principle. This is not the book to start with, but one that you should read after you've been doing visualization for a while. It will help you develop an eye for what works and what doesn't work.

</div>

### Recommended books

![Book cover of Visualizing Data](../images/cleveland-bookcover.jpg)

<div class="notes">

I learned more from this book than any other. It might be a bit dated today, but it helps you understand why a graph works from the underlying issues of the psychology of perception. This is also a good book to read if you want to see some of the pioneering changes that were made in data visualization just before the turn of the century. If you are just starting out in data visualization, this is not going to be your first book.

</div>

### Recommended books

![Book cover of Grammar of Graphics](../images/wilkinson-bookcover.jpg)

<div class="notes">

This book has had a tremendous impact on data visualizaiton software, but it took ten years because no one really understood what the book was trying to say. It is a very difficult read, full of theory. It is probably best for those who write software rather than those who use it.

</div>

### Recommended books

![Book cover of Visual Revelations](../images/wainer-bookcover.jpg)

<div class="notes">

Howard Wainer is a great story teller and you learn a lot from each story that he tells. This book takes a look at data visualization from many many years ago and points out lessons that you can learn from this. It's sort of like teaching through analogy.

</div>

### Recommended books

![Book cover of Creating More Effective Graphs](../images/robbins-bookcover.jpg)

<div class="notes">

This book is very applied and is an excellent starter book for anyone wanting to learn more about data visualization. I found it a bit simplistic in parts, but after having read so many other books, perhaps that is unavoidable.

</div>

### Recommended books

![Book cover of Creating More Effective Graphs](../images/few-bookcover.jpg)

<div class="notes">

This is another very applied book. Both are equally good, but Robbins book seems a bit friendlier to me.

</div>

```{r save-everything}
save.image("../data/improving.RData")